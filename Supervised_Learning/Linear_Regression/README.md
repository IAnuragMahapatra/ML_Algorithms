# Linear Regression

## Overview
Linear Regression is one of the fundamental algorithms in machine learning, used for predicting a continuous output variable based on one or more input features. This implementation demonstrates both Simple Linear Regression (one feature) and Multiple Linear Regression (multiple features).

## Theory
Linear Regression works by establishing a linear relationship between input features (X) and the output variable (y) using the equation:
y = mx + b
where:
- y is the predicted output
- m is the slope (coefficient)
- x is the input feature
- b is the y-intercept

## Implementation Details
The notebook includes:
1. Data preprocessing and exploration
2. Model training and evaluation
3. Visualization of results
4. Performance metrics analysis

## Dataset
The included dataset demonstrates real-world application of Linear Regression, featuring:
- Input features: Various numerical predictors
- Target variable: Continuous numerical output
- Sample size: Sufficient for training and testing

## Usage
Open the Jupyter notebook to see the step-by-step implementation and explanations.